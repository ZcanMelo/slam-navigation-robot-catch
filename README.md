# slam-navigation-robot-catch
æœ¬é¡¹ç›®æ˜¯ä¸º 2024 Go Sim China å±•ç¤ºå¼€å‘çš„ç¤ºèŒƒé¡¹ç›®ã€‚
é¡¹ç›®ç›®æ ‡æ˜¯å®ç°ä»¥ä¸‹æµç¨‹ï¼šé€šè¿‡ Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œåˆ©ç”¨åƒé—®å¤§æ¨¡å‹æå–æŒ‡ä»¤å…³é”®è¯ï¼Œå°†å…³é”®è¯ä¼ é€’ç»™æœºæ¢°è‡‚ã€‚åŒæ—¶ï¼Œè½¦è¾†æ¥æ”¶ä¿¡å·åï¼ŒåŸºäºæ¿€å…‰ SLAM å®Œæˆå®šä½ï¼Œå¹¶ç»“åˆé¢„è®¾è·¯çº¿è¿›è¡Œè‡ªä¸»å¯¼èˆªã€‚å½“è½¦è¾†åˆ°è¾¾æŒ‡å®šä½ç½®åï¼Œå‘é€ä¿¡å·è‡³æœºæ¢°è‡‚æ¨¡å—ï¼Œæœºæ¢°è‡‚é€šè¿‡ YOLOv5 è¿›è¡Œç›®æ ‡è¯†åˆ«å¹¶å®ŒæˆæŠ“å–ä»»åŠ¡ã€‚

This project is a demonstration developed for the 2024 Go Sim China event.
The objective is to achieve the following workflow: perform speech recognition using Whisper, extract command keywords using the Qianwen large language model, and transmit the keywords to the robotic arm. Meanwhile, the vehicle receives the signal, localizes itself using LiDAR SLAM, and navigates autonomously based on a predefined route. Upon reaching the target location, the vehicle sends a signal to the robotic arm, which then uses YOLOv5 for object detection and completes the grasping task.

## ğŸ“º é¡¹ç›®è§†é¢‘

è§†é¢‘ä»‹ç»ï¼š[ç‚¹å‡»è§‚çœ‹é¡¹ç›®æ¼”ç¤ºè§†é¢‘ï¼ˆyoutubeï¼‰](https://www.youtube.com/watch?v=pquhG_lcHEE)

## ğŸ“„ é¡¹ç›®è¯¦ç»†æ–‡æ¡£

è¯¦ç»†é¡¹ç›®ä»‹ç»è¯·å‚è€ƒï¼š[ç‚¹å‡»ä¸‹è½½é¡¹ç›®æ–‡æ¡£](autonomous_manual.pdf)

